<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<description>kula41 Tech Space, share technology post</description>
		<link>/</link>
		<atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>curl 命令行下载工具使用方法小结</title>
				<description>&lt;p&gt;curl 命令行下载工具使用方法小结&lt;/p&gt;

&lt;p&gt;1) 
二话不说，先从这里开始吧！ 
curl http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;回车之后，www.yahoo.com 的html就稀里哗啦地显示在屏幕上了~~~~~&lt;/p&gt;

&lt;p&gt;2) 
嗯，要想把读过来页面存下来，是不是要这样呢？ 
curl http://www.yahoo.com &amp;gt; page.html&lt;/p&gt;

&lt;p&gt;当然可以，但不用这么麻烦的！ 
用curl的内置option就好，存下http的结果，用这个option: -o 
curl -o page.html http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;这样，你就可以看到屏幕上出现一个下载页面进度指示。等进展到100%，自然就OK咯&lt;/p&gt;

&lt;p&gt;3) 
什么什么？！访问不到？肯定是你的proxy没有设定了。 
使用curl的时候，用这个option可以指定http访问所使用的proxy服务器及其端口： -x 
curl -x 123.45.67.89:1080 -o page.html http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;4) 
访问有些网站的时候比较讨厌，他使用cookie来记录session信息。 
像IE/NN这样的浏览器，当然可以轻易处理cookie信息，但我们的curl呢？….. 
我们来学习这个option: -D &amp;lt;– 这个是把http的response里面的cookie信息存到一个特别的文件中去 
curl -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;这样，当页面被存到page.html的同时，cookie信息也被存到了cookie0001.txt里面了&lt;/p&gt;

&lt;p&gt;5） 
那么，下一次访问的时候，如何继续使用上次留下的cookie信息呢？要知道，很多网站都是靠监视你的cookie信息， 
来判断你是不是不按规矩访问他们的网站的。 
这次我们使用这个option来把上次的cookie信息追加到http request里面去： -b 
curl -x 123.45.67.89:1080 -o page1.html -D cookie0002.txt -b cookie0001.txt http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;这样，我们就可以几乎模拟所有的IE操作，去访问网页了！&lt;/p&gt;

&lt;p&gt;6） 
稍微等等~~~~~我好像忘记什么了~~~~~ 
对了！是浏览器信息~~~~&lt;/p&gt;

&lt;p&gt;有些讨厌的网站总要我们使用某些特定的浏览器去访问他们，有时候更过分的是，还要使用某些特定的版本~~~~ 
NND，哪里有时间为了它去找这些怪异的浏览器呢！？&lt;/p&gt;

&lt;p&gt;好在curl给我们提供了一个有用的option，可以让我们随意指定自己这次访问所宣称的自己的浏览器信息： -A 
curl -A “Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)” -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;这样，服务器端接到访问的要求，会认为你是一个运行在Windows 2000上的IE6.0，嘿嘿嘿，其实也许你用的是苹果机呢！&lt;/p&gt;

&lt;p&gt;而”Mozilla/4.73 [en] (X11; U; Linux 2.2; 15 i686”则可以告诉对方你是一台PC上跑着的Linux，用的是Netscape 4.73，呵呵呵&lt;/p&gt;

&lt;p&gt;7） 
另外一个服务器端常用的限制方法，就是检查http访问的referer。比如你先访问首页，再访问里面所指定的下载页，这第二次访问的 referer地址就是第一次访问成功后的页面地址。这样，服务器端只要发现对下载页面某次访问的referer地址不是首页的地址，就可以断定那是个盗连了~~~~~&lt;/p&gt;

&lt;p&gt;讨厌讨厌~~~我就是要盗连~~~~~！！ 
幸好curl给我们提供了设定referer的option： -e 
curl -A “Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)” -x 123.45.67.89:1080 -e “mail.yahoo.com” -o page.html -D cookie0001.txt http://www.yahoo.com&lt;/p&gt;

&lt;p&gt;这样，就可以骗对方的服务器，你是从mail.yahoo.com点击某个链接过来的了，呵呵呵&lt;/p&gt;

&lt;p&gt;8） 
写着写着发现漏掉什么重要的东西了！—– 利用curl 下载文件&lt;/p&gt;

&lt;p&gt;刚才讲过了，下载页面到一个文件里，可以使用 -o ，下载文件也是一样。 
比如， curl -o 1.jpg http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPG 
这里教大家一个新的option： -O 
大写的O，这么用： curl -O http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPG 
这样，就可以按照服务器上的文件名，自动存在本地了！&lt;/p&gt;

&lt;p&gt;再来一个更好用的。 
如果screen1.JPG以外还有screen2.JPG、screen3.JPG、….、screen10.JPG需要下载，难不成还要让我们写一个script来完成这些操作？ 
不干！ 
在curl里面，这么写就可以了： 
curl -O http://cgi2.tky.3web.ne.jp/~zzh/screen[1-10].JPG&lt;/p&gt;

&lt;p&gt;呵呵呵，厉害吧？！~~~&lt;/p&gt;

&lt;p&gt;9） 
再来，我们继续讲解下载！ 
curl -O http://cgi2.tky.3web.ne.jp/~/[001-201].JPG&lt;/p&gt;

&lt;p&gt;这样产生的下载，就是 
~zzh/001.JPG 
~zzh/002.JPG 
… 
~zzh/201.JPG 
~nick/001.JPG 
~nick/002.JPG 
… 
~nick/201.JPG&lt;/p&gt;

&lt;p&gt;够方便的了吧？哈哈哈&lt;/p&gt;

&lt;p&gt;咦？高兴得太早了。 
由于zzh/nick下的文件名都是001，002…，201，下载下来的文件重名，后面的把前面的文件都给覆盖掉了~~~&lt;/p&gt;

&lt;p&gt;没关系，我们还有更狠的！ 
curl -o #2_#1.jpg http://cgi2.tky.3web.ne.jp/~/[001-201].JPG&lt;/p&gt;

&lt;p&gt;–这是…..自定义文件名的下载？ 
–对头，呵呵！&lt;/p&gt;

&lt;h1 id=&quot;zzhnick&quot;&gt;1是变量，指的是这部分，第一次取值zzh，第二次取值nick&lt;/h1&gt;
&lt;p&gt;#2代表的变量，则是第二段可变部分—[001-201]，取值从001逐一加到201 
这样，自定义出来下载下来的文件名，就变成了这样： 
原来： ~zzh/001.JPG —&amp;gt; 下载后： 001-zzh.JPG 
原来： ~nick/001.JPG —&amp;gt; 下载后： 001-nick.JPG&lt;/p&gt;

&lt;p&gt;这样一来，就不怕文件重名啦，呵呵&lt;/p&gt;

&lt;p&gt;9） 
继续讲下载 
我们平时在windows平台上，flashget这样的工具可以帮我们分块并行下载，还可以断线续传。 
curl在这些方面也不输给谁，嘿嘿&lt;/p&gt;

&lt;p&gt;比如我们下载screen1.JPG中，突然掉线了，我们就可以这样开始续传 
curl -c -O http://cgi2.tky.3wb.ne.jp/~zzh/screen1.JPG&lt;/p&gt;

&lt;p&gt;当然，你不要拿个flashget下载了一半的文件来糊弄我~~~~别的下载软件的半截文件可不一定能用哦~~~&lt;/p&gt;

&lt;p&gt;分块下载，我们使用这个option就可以了： -r 
举例说明 
比如我们有一个http://cgi2.tky.3web.ne.jp/~zzh/zhao1.mp3 要下载（赵老师的电话朗诵 :D ） 
我们就可以用这样的命令： 
curl -r 0-10240 -o “zhao.part1” http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.mp3 &amp;amp;\ 
curl -r 10241-20480 -o “zhao.part1” http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.mp3 &amp;amp;\ 
curl -r 20481-40960 -o “zhao.part1” http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.mp3 &amp;amp;\ 
curl -r 40961- -o “zhao.part1” http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.mp3&lt;/p&gt;

&lt;p&gt;这样就可以分块下载啦。 
不过你需要自己把这些破碎的文件合并起来 
如果你用UNIX或苹果，用 cat zhao.part* &amp;gt; zhao.mp3就可以 
如果用的是Windows，用copy /b 来解决吧，呵呵&lt;/p&gt;

&lt;p&gt;上面讲的都是http协议的下载，其实ftp也一样可以用。 
用法嘛， 
curl -u name:passwd ftp://ip:port/path/file 
或者大家熟悉的 
curl ftp://name:passwd@ip:port/path/file&lt;/p&gt;

&lt;p&gt;10) 
说完了下载，接下来自然该讲上传咯 
上传的option是 -T&lt;/p&gt;

&lt;p&gt;比如我们向ftp传一个文件： curl -T localfile -u name:passwd ftp://upload_site:port/path/&lt;/p&gt;

&lt;p&gt;当然，向http服务器上传文件也可以 
比如 curl -T localfile http://cgi2.tky.3web.ne.jp/~zzh/abc.cgi 
注意，这时候，使用的协议是HTTP的PUT method&lt;/p&gt;

&lt;p&gt;刚才说到PUT，嘿嘿，自然让老服想起来了其他几种methos还没讲呢！ 
GET和POST都不能忘哦。&lt;/p&gt;

&lt;p&gt;http提交一个表单，比较常用的是POST模式和GET模式&lt;/p&gt;

&lt;p&gt;GET模式什么option都不用，只需要把变量写在url里面就可以了 
比如： 
curl http://www.yahoo.com/login.cgi?user=nickwolfe&amp;amp;password=12345&lt;/p&gt;

&lt;p&gt;而POST模式的option则是 -d&lt;/p&gt;

&lt;p&gt;比如，curl -d “user=nickwolfe&amp;amp;password=12345” http://www.yahoo.com/login.cgi 
就相当于向这个站点发出一次登陆申请~~~~~&lt;/p&gt;

&lt;p&gt;到底该用GET模式还是POST模式，要看对面服务器的程序设定。&lt;/p&gt;

&lt;p&gt;一点需要注意的是，POST模式下的文件上的文件上传，比如&lt;/p&gt;
&lt;form method=&quot;POST&quot; enctype=&quot;multipar/form-data&quot; action=&quot;http://cgi2.tky.3web.ne.jp/~zzh/up_file.cgi&quot;&gt; 
&amp;lt;input type=file name=upload&amp;gt; 
&amp;lt;input type=submit name=nick value=&quot;go&quot;&amp;gt; 
&lt;/form&gt;
&lt;p&gt;这样一个HTTP表单，我们要用curl进行模拟，就该是这样的语法： 
curl -F upload=@localfile -F nick=go http://cgi2.tky.3web.ne.jp/~zzh/up_file.cgi&lt;/p&gt;

&lt;p&gt;罗罗嗦嗦讲了这么多，其实curl还有很多很多技巧和用法 
比如 https的时候使用本地证书，就可以这样 
curl -E localcert.pem https://remote_server&lt;/p&gt;

&lt;p&gt;再比如，你还可以用curl通过dict协议去查字典~~~~~ 
curl dict://dict.org/d:computer&lt;/p&gt;
</description>
				<pubDate>Mon, 20 Apr 2015 00:00:00 +0800</pubDate>
				<link>/linux/2015/04/20/linux-curl.html</link>
				<guid isPermaLink="true">/linux/2015/04/20/linux-curl.html</guid>
			</item>
		
			<item>
				<title>如何让百度快速收录</title>
				<description>&lt;p&gt;如何让百度快速收录&lt;/p&gt;

&lt;p&gt;我们都知道，一个网站，要先有收录，才有排名，有了排名，才有流量。很多学员问我这样一个问题，为什么一个新站上线很久，百度却迟迟不收，我一个一个回答的都累了，那我们今天就在这里详细讲解一下新站如何实现让百度秒收的几个注意事项。&lt;/p&gt;

&lt;p&gt;网站上线后,千万不要到百度URL的提交入口去提交,因为你一旦提交了，那么你就被百度对于新站的算法判定为你提交的这是一个新站，而百度对于新站的算法相对于百度对蜘蛛爬行到的链接算法是有很大差异的。对于新站的算法，我们这里暂且称它为《百度新站算法》。百度对于新站短时间内不会马上收录的,而是会有一个评估时间,这个时间段内加入百度觉得你的网站内容是有价值的,那么它就会把这个时间段缩短从而提前收录;但是它如果觉得这个站的内容一般情况,也不会完全是抄袭的它就会等评估时间过后再收录;另外一种情况是倘若这个站是在很差，完全原封不动照抄的,那它就会把这个站判断为较差质量的网站，百度的这个评估时间段一般为30天左右。所以新手千万不要心急，新站上线后不管它，直接扔外链，因为百度对于蜘蛛爬行到的外链而进行的直接质量评估,远比你提交获得的算法来的块。百度通过外链质量的算法,如果计算出的得分较高,它就会立即收录。&lt;/p&gt;

&lt;p&gt;那么在发外链的过程中，绝大部分的外链是发在百度贴吧、百度知道以及百度经验和百度文库上。因为高权重的外链，是实现新站秒收的一个重要因素。再者你可以一边配合友情链接的使用，一个高质的友链可以给你的新站导入不少的权重和流量以及蜘蛛爬取的密度，那么友链我们需要注意的是链你的站没有没降权，这方面你可以参考PR或者快照更新时间，挂友链的数量密度不可太高，一般来说1天1个，然后累积到一定数量即可。这里说下原因，这是因为短时间内百度发现你增加了大量的友链，它也会认为也是从链接工厂购买来的。所以加入你购买了很多友链，不要一天就挂上去。再者就是挂上去后我们还需经常查看，配合日常点击，充分发挥友链对你网站的影响。还要对一些不友好的友链及时撤掉，打个比方说你的友链里有一个被百度K了，那么你的站也会受牵连。&lt;/p&gt;

&lt;p&gt;终上所述,我们大概知道了百度的一个收录原理，那么新站的站长也可以按以上方式去做。这也是我做了很多个站的出来的一点经验，那么怎么做呢，好的，那我们就讲一下网上流传的让百度5分钟秒收的做法：&lt;/p&gt;

&lt;p&gt;一、在还没有完善整站的时候，增删篇幅较大的时候，要注意设置robots的屏蔽各种蜘蛛，以免搜索引擎误认为你的站不稳定。&lt;/p&gt;

&lt;p&gt;　 二、新站完成后需要对站内进行相关的检查。例如关键词的密度是否合理、有没有存在死链、是否有百度的禁词，这些都是百度作为判定的一个标准，一定要引起重视。&lt;/p&gt;

&lt;p&gt;　 三、内容要尽量丰富，最好是能有若干篇原创文章，假如实在没有，呵呵，弄几遍伪原创也是可以的。&lt;/p&gt;

&lt;p&gt;　 四、用配置较好的主机或空间，保证打开的速度，完全加载成功的时间不超过5秒。&lt;/p&gt;

&lt;p&gt;　 五、以上是做站内优化需要注意的一些问题，做完了我们就可以撤掉robots的屏蔽，进行蜘蛛的吸引。吸引蜘蛛要去可以秒收的网站吸引蜘蛛，只有这样才能实现网站的秒收。至于秒收的网站有很多,像网易论坛、新浪博客、天涯社区、seowhy、A5等。&lt;/p&gt;

&lt;p&gt;　　
 以上就是实现百度5分钟秒收的方法，新手只要照着做，一定能实现快速收录，这里再提及一下极少见的情况，就是有些站过了一个月的审核期仍然没有被收录，这种情况就要考虑一下你的域名是否之前被注册过并且被百度K过，百度对于K过的域名非常严格永不收录，那么如何判断域名是否被K过，方法是这样的，可以在百度输入：stie:你的域名和domain:你的域名，如果site无记录，而domain却出现很多的记录，那么极有可能是被K过的。另外还可以通过Alexa历史排名和Whois信息查询域名是否被用过。&lt;/p&gt;

&lt;p&gt;本篇文章转自：&lt;a href=&quot;http://www.heimaoseojishu.com/forum.php?mod=viewthread&amp;amp;tid=29&amp;amp;fromuid=697&quot;&gt;新站如何让百度快速收录-黑帽SEO技术网原创文章&lt;/a&gt;
(出处: 黑帽SEO技术网)&lt;/p&gt;
</description>
				<pubDate>Mon, 20 Apr 2015 00:00:00 +0800</pubDate>
				<link>/seo/2015/04/20/baidu-include.html</link>
				<guid isPermaLink="true">/seo/2015/04/20/baidu-include.html</guid>
			</item>
		
			<item>
				<title>使用puppet去部署openstack</title>
				<description>&lt;p&gt;使用puppet去部署openstack&lt;/p&gt;

&lt;h2 id=&quot;puppet&quot;&gt;puppet简介&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Puppet是一个IT基础设施自动化管理工具，帮助系统管理员管理基础设施整个生命周期的供应(provisioning),配置(configuration)，联动(orchestration)及报告(reporting)。&lt;/li&gt;
  &lt;li&gt;基于puppet可以实现自动化重复任务，快速部署关键性应用以及在本地或者云端完成主动管理变更和快速部署扩展架构。&lt;/li&gt;
  &lt;li&gt;当然，对于管理员它是抽象的，只依赖于facter工具（可以检索出不同系统的基本信息）和ruby语言环境（主要以模版的形式来开发）。&lt;/li&gt;
  &lt;li&gt;Puppet能管理40多种资源，架构模式是master/agent管理与被管理的关系并非主从关系。
## puppet工作原理 ##&lt;/li&gt;
  &lt;li&gt;（1）客户端Puppetd向Master发起认证请求，或使用带签名的证书。&lt;/li&gt;
  &lt;li&gt;（2）Master告诉Client你是合法的。&lt;/li&gt;
  &lt;li&gt;（3）客户端Puppetd调用Facter，Facter探测出主机的一些变量，例如主机名、内存大小、IP地址等。Puppetd将这些信息通过SSL连接发送到服务器端。&lt;/li&gt;
  &lt;li&gt;（4）服务器端的PuppetMaster检测客户端的主机名，然后找到manifest对应的node配置，并对该部分内容进行解析。Facter送过来的信息可以作为变量处理，node牵涉到的代码才解析，其他没牵涉的代码不解析。解析分为几个阶段，首先是语法检查，如果语法错误就报错;如果语法没错，就继续解析，解析的结果生成一个中间的“伪代码”(catelog)，然后把伪代码发给客户端。&lt;/li&gt;
  &lt;li&gt;（5）客户端接收到“伪代码”，并且执行。&lt;/li&gt;
  &lt;li&gt;（6）客户端在执行时判断有没有File文件，如果有，则向fileserver发起请求。&lt;/li&gt;
  &lt;li&gt;（7）客户端判断有没有配置Report，如果已配置，则把执行结果发送给服务器。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;（8）服务器端把客户端的执行结果写入日志，并发送给报告系统。
## 认证过程 ##
 任何一台puppet客户端想要获取服务器的配置信息第一步必须先要认证完毕。具体认证过程如下：&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;（1）puppet客户端请求节点配置。&lt;/li&gt;
  &lt;li&gt;（2）puppetmaster进行SSL认证。&lt;/li&gt;
  &lt;li&gt;（3）将信息日志写入cactlog。&lt;/li&gt;
  &lt;li&gt;（4）puppet解析器解释代码（包括错误检查以及语法检查）,并写入日志。&lt;/li&gt;
  &lt;li&gt;（5）客户端发送日志。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;（6）ssl认证授权结束，整个流程结束。
## puppet目录结构 ##
puppet.conf主配置文件&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;fileserver.conf允许访问的文件控制&lt;/li&gt;
  &lt;li&gt;auth.conf访问权限配置&lt;/li&gt;
  &lt;li&gt;autosign.conf自动验证配置文件&lt;/li&gt;
  &lt;li&gt;manifests文件存储目录(puppet会先读取该目录的.pp文件&lt;site.pp&gt;)&lt;/site.pp&gt;&lt;/li&gt;
  &lt;li&gt;site.conf全局配置文件&lt;/li&gt;
  &lt;li&gt;modules定义模块&lt;/li&gt;
  &lt;li&gt;templates模块配置目录&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;应用背景：&lt;/h2&gt;
&lt;p&gt;目前puppet官方有根据openstack各种环境编辑好了一整套部署脚本，这一套也已经上传到社区（比如github）给一些相关人士进行维护并更新。我们只要获取那些脚本，在根据我们自己的需求来封装自己的一个类，这个类就是关于怎么调用那些人家已经完善得非常好的各种相关openstack组件模块。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;操作系统：centos6.5&lt;/li&gt;
  &lt;li&gt;Openstack版本：havana icehouse juno&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Puppet版本：2.7或以上（如果一些脚本需要的话可能要把版本更新到3.x以上的）
## 安装puppet ##
  设置源：
  rpm -ivh http://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm
  安装：
  Agent端：yum install puppet
  Server端：yum install puppet-server
  获取脚本：
  puppet module install puppetlabs-openstack
  下载git上面的脚本：
  cd /etc/puppet/modules
  git clone git://github.com/stackforge/puppet-openstack.git openstack
  cd openstack
  gem install librarian-puppet
  librarian-puppet install –path ../
## openstack模块 ##
  [root@puppet modules]# tree -L 1
  .
  ├── 99cloud
  ├── apache
  ├── ceilometer
  ├── certmonger
  .
  .
  .
  ├── vlan
  ├── vswitch
  └── xinetd&lt;/p&gt;

    &lt;p&gt;50 directories, 0 files&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这50个左右的模块里面控制整个openstack流程安装部署的就在openstack这个模块里面，
在openstack这个模块里面主要是把各个openstack各个组件模块调用起来最后形成了可以灵活地运用各种参数去部署openstack的脚本。这是由于openstack有很多配置文件以及后面要更变配置，所有才有了如此之多的参数。当然，你可以根据自己的需要，比如一些组件你不安装或者一些配置是不需要的，然后自己组成一个模块之类的。
## 部署 ##
在自己脚本完成后并测试没有什么语法错误就可以开始部署安装，当然在这之前肯定要经过大量的测试来完善自己的脚本：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;There are two kinds of use: 
---1 
	stand-alone mode: direct calling scripts
	allinone #sudo puppet apply -e &quot;class { 99cloud::allinone: }&quot;
	controller   #sudo puppet apply -e &quot;class { 99cloud::controller: }&quot;
	only compute #sudo puppet apply -e &quot;class { 99cloud::compute: }&quot;
---2
	server-agent mode:
	a: pick out one end as a service
	b: edit /etc/puppet/manifests/site.pp (If not,please create)
	c: depending on the fqdn(hostname+domain) to deploy different nodes
For your controller node, you need to assign your node the controller role. For example:
```
node 'control.localdomain' { 
	include 99cloud::controller
}
```
allinone:
include 99cloud::allinone
```
compute:
	include 99cloud::compute
```
 d: on your node exec:
 #puppet agent -t --server 'service of fqdn' 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;也就是说主要有2种部署方式，一种是单机模式，另一种是C/S模式。如果你的服务器有上几十台以上就需要用到C/S模式，否则尽量用单机模式来部署。这样既节省时间，又方便控制各个服务器。
从裸机到openstack平台&lt;/p&gt;

&lt;p&gt;简而言之，就是先对一台裸机进行PXE（安装系统）之后再利用puppet把openstack平台架起来&lt;/p&gt;
</description>
				<pubDate>Tue, 03 Mar 2015 00:00:00 +0800</pubDate>
				<link>/deploy/2015/03/03/puppet.html</link>
				<guid isPermaLink="true">/deploy/2015/03/03/puppet.html</guid>
			</item>
		
			<item>
				<title>Linux用DD命令测试磁盘读写速度</title>
				<description>&lt;p&gt;Linux用DD命令测试磁盘读写速度&lt;/p&gt;

&lt;p&gt;　　当然这篇文章是写给我这种小白的，高手请绕路！dd是Linux/UNIX 下的一个非常有用的命令，作用是用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换，所以可以用来测试硬盘的读写能力~
下面直接介绍几种常见的DD命令，先看一下他的区别~&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dd bs=64k count=4k if=/dev/zero of=test
dd bs=64k count=4k if=/dev/zero of=test; sync
dd bs=64k count=4k if=/dev/zero of=test conv=fdatasync
dd bs=64k count=4k if=/dev/zero of=test oflag=dsync
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这四条DD命令区别在于内存中写缓存的处理方式。&lt;/p&gt;

&lt;h2 id=&quot;dd-bs64k-count4k-ifdevzero-oftest&quot;&gt;1.dd bs=64k count=4k if=/dev/zero of=test&lt;/h2&gt;
&lt;p&gt;　　没有加任何参数，dd默认的方式不包括“同步(sync)”命令。也就是说，dd命令完成前并没有让系统真正把文件写到磁盘上。所以以上命令只是单纯地把这128MB的数据读到内存缓冲当中（写缓存[write cache]）。所以你得到的将是一个超级快的速度。因为其实dd给你的只是读取速度，直到dd完成后系统才开始真正往磁盘上写数据，但这个速度你是看不到了。所以如果这个速度很快，没有什么作用。
实际运行结果：
268435456 bytes (268 MB) copied, 1.3529 seconds, 198 MB/s&lt;/p&gt;

&lt;h2 id=&quot;dd-bs64k-count4k-ifdevzero-oftest-sync&quot;&gt;2.dd bs=64k count=4k if=/dev/zero of=test; sync&lt;/h2&gt;
&lt;p&gt;　　和前面1中的完全一样。分号隔开的只是先后两个独立的命令。当sync命令准备开始往磁盘上真正写入数据的时候，前面dd命令已经把错误的“写入速度”值显示在屏幕上了。所以你还是得不到真正的写入速度。
实际运行结果：
268435456 bytes (268 MB) copied, 0.522815 seconds, 513 MB/s&lt;/p&gt;

&lt;h2 id=&quot;dd-bs64k-count4k-ifdevzero-oftest-convfdatasync&quot;&gt;3.dd bs=64k count=4k if=/dev/zero of=test conv=fdatasync&lt;/h2&gt;
&lt;p&gt;　　加入这个参数后，dd命令执行到最后会真正执行一次“同步(sync)”操作，所以这时候你得到的是读取这128M数据到内存并写入到磁盘上所需的时间，这样算出来的时间才是比较符合实际使用结果的。
实际运行结果：
268435456 bytes (268 MB) copied, 2.8046 seconds, 95.7 MB/s&lt;/p&gt;

&lt;h2 id=&quot;dd-bs64k-count4k-ifdevzero-oftest-oflagdsync&quot;&gt;4.dd bs=64k count=4k if=/dev/zero of=test oflag=dsync&lt;/h2&gt;
&lt;p&gt;　　加入这个参数后，dd在执行时每次都会进行同步写入操作。也就是说，这条命令每次读取64k后就要先把这64k写入磁盘，然后再读取下面这64k，一共重复128次。这可能是最慢的一种方式了，因为基本上没有用到写缓存(write cache)。
实际运行结果：
268435456 bytes (268 MB) copied, 3.40069 seconds, 78.9 MB/s
　　一般来说，第四种方法是最严格的，可以模拟数据库的插入操作，所以很慢，也是用来测试vps硬盘性能标准的一条标杆，一般来说测试结果，如果超过10M，对正常建站就无影响。超过50M，就是非常给力状态，看了这个vps硬盘性能非常的好，DD速度达到了78.9MB/s。
　　在这几条命令中，bs=64k表示同时读入/输出的块大小为64k个字节，count=4k表示拷贝块的个数为4000个，如果测试再严格一点，我们运行1G数据量的DD：
dd if=/dev/zero of=test bs=64k count=16k oflag=dsync
表示每个块大小为64k个字节，测试16k个数量的块，实际测试结果：
1073741824 bytes (1.1 GB) copied, 18.9098 seconds, 56.8 MB/s&lt;/p&gt;

</description>
				<pubDate>Sun, 01 Feb 2015 00:00:00 +0800</pubDate>
				<link>/hardware/2015/02/01/Linux-dd.html</link>
				<guid isPermaLink="true">/hardware/2015/02/01/Linux-dd.html</guid>
			</item>
		
			<item>
				<title>Git学习及下载资源</title>
				<description>&lt;p&gt;保存Git源码管理原理学习及下载链接&lt;/p&gt;

&lt;p&gt;Git学习资源&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://developer.51cto.com/art/201111/302195.htm&quot;&gt;http://developer.51cto.com/art/201111/302195.htm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/luckarecs/article/details/7427605&quot;&gt;http://blog.csdn.net/luckarecs/article/details/7427605&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.open-open.com/lib/list/282?pn=2&quot;&gt;http://www.open-open.com/lib/list/282?pn=2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Git下载链接&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://msysgit.github.com/&quot;&gt;http://msysgit.github.com/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://code.google.com/p/gitextensions/downloads/list&quot;&gt;http://code.google.com/p/gitextensions/downloads/list&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://gitscc.codeplex.com/&quot;&gt;http://gitscc.codeplex.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Wed, 21 Jan 2015 00:00:00 +0800</pubDate>
				<link>/resource/2015/01/21/git-resource.html</link>
				<guid isPermaLink="true">/resource/2015/01/21/git-resource.html</guid>
			</item>
		
			<item>
				<title>存储技术之RAID</title>
				<description>&lt;p&gt;存储技术如今已经越来越重要，而且在云计算时代，涌现出了很多专注于云存储的厂商。存储技术本身也十分复杂，从硬件到协议到软件到接口几乎覆盖计算机科学的方方面面。笔者借助《大话存储II》这本书，开始了这块知识空白的补充。本文的图片均来源于网络。&lt;/p&gt;

&lt;p&gt;一块磁盘的容量有限，速度有限，如果需要更大的存储空间，更快的速度怎么办呢？而且如果数据可靠性要求很高，如果一块磁盘坏了，是否有办法保持数据不丢失呢？&lt;code&gt;RAID&lt;/code&gt;(Redundant Array of Independent Disks)因此而生。无论是哪种RAID，其基本思想不外乎如下几种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果一块硬盘不够用，那么多加几块&lt;/li&gt;
  &lt;li&gt;如果一块硬盘不够快，那么让多块硬盘同时参与IO&lt;/li&gt;
  &lt;li&gt;如果要考虑硬盘损坏，那么让数据多存几份，或者利用某种校验算法，保证数据能够恢复&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid-0&quot;&gt;RAID 0&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;RAID 0&lt;/code&gt;将两块/多块硬盘合并成一块逻辑磁盘。比如两块500GB的硬盘组建RAID 0，那么在系统中我们可以看到有一块1TB的逻辑磁盘，而并不能看到是两块物理硬盘。RAID 0将数据的读写同时分摊到多块磁盘上，也就是说，数据会被控制器分割后写入多块盘，读取时也会同时调动多块盘一起读，最后由控制器组合后返回上层操作系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/RAID_0.svg/130px-RAID_0.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出RAID 0在读写效率上要比单盘要高，因为有很大概率调动多块磁盘同时操作。对于上层操作系统而言，并不感知。操作系统只是觉得可用的扇区变多了，而且对于数据被“分割”和“合并”这样的事情也一无所知。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点：速度快、效率高、容量提升&lt;/li&gt;
  &lt;li&gt;缺点：无备份，容易丢失数据&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid-1&quot;&gt;RAID 1&lt;/h2&gt;

&lt;p&gt;为了解决磁盘损坏导致所有数据丢失，&lt;code&gt;RAID 1&lt;/code&gt;将数据原样复制了一份到另一个磁盘，这样能够在一块盘损坏的情况下，保留数据。而且读数据的时候可以同时在两块盘上读，速度提升了，因为它们的数据是完全一样的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/RAID_1.svg/130px-RAID_1.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点：读速度快，有备份&lt;/li&gt;
  &lt;li&gt;缺点：容量无提升，写效率低&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid-2&quot;&gt;RAID 2&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;RAID 2&lt;/code&gt;最初是希望在RAID 0中加入RAID 1的可靠性。原理是将数据打散成bit，平均存到不同的磁盘上，并利用&lt;a href=&quot;http://zh.wikipedia.org/zh-cn/%E6%B1%89%E6%98%8E%E7%A0%81&quot;&gt;Hanmming Code&lt;/a&gt;算法将校验位写入到校验盘，在读取数据时反过来校验数据。如果某块磁盘损坏，可以通过校验得知，并通过计算得到原本坏盘上的数据。汉明码需要比较多的校验盘，如果数据盘有4块，校验盘需要3块； 如果数据盘有7块，校验盘需要4块。RAID 2最少需要3块硬盘才能组建。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/RAID2_arch.svg/300px-RAID2_arch.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点：在RAID 0的基础上加入校验功能&lt;/li&gt;
  &lt;li&gt;缺点：校验盘太多&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid-3&quot;&gt;RAID 3&lt;/h2&gt;

&lt;p&gt;针对RAID 2校验盘太多的情况，利用更为简单的异或运算，创建了RAID 3。RAID 3的思想也是将数据打散存在不同的数据盘上，并将校验位单独存放在校验盘，但是无论数据盘有多少，RAID 3的校验盘只需要一块，因为RAID 3是将数据位进行异或运算得到的校验位。不过这样做只能容许一块数据盘的损坏，在得知那块盘损坏的情况下，可以根据校验盘和其他的数据盘计算出损坏的盘上的数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/RAID_3.svg/220px-RAID_3.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点：在RAID 2的基础上，减少了校验盘的数量，并行度也有所提高&lt;/li&gt;
  &lt;li&gt;缺点：无法并发IO，因为每次IO都需要牵动所有的磁盘，当然RAID 2也有此缺点&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid-4&quot;&gt;RAID 4&lt;/h2&gt;

&lt;p&gt;RAID 2和RAID 3虽然改进了读写效率，但是每次IO都要牵动所有的数据盘和校验盘，而每块磁盘同一时刻只能进行一次IO是真理，所以RAID 2 和RAID 3无法实现并行IO。要实现并行IO，就必须有空闲的磁盘不被IO占用，以便其他的IO使用空闲的磁盘。基于这一点，RAID 4在RAID 3的基础上，索性将数据量小的IO，全部写入一个磁盘，而不是分散在所有数据盘。这样，在读取数据的时候就有可能不牵动所有的数据盘，而空出其他的数据盘处理其他的IO。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/RAID_4.svg/220px-RAID_4.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;缺点：实际上这个想法忽略了一个很重要的问题，就是无论数据盘如何规划，任何一个IO都要动用校验盘，所以校验盘成了热点。相比RAID 3，RAID 4没有提升多少读写性能。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid-5&quot;&gt;RAID 5&lt;/h2&gt;

&lt;p&gt;RAID 4几乎没有价值，但是在RAID 4的思想基础上，针对校验盘是热点盘的问题，人们又发明了RAID 5。RAID 5并没有固定的校验盘，而是将校验数据打散存放到数据盘中。这样，随着数据盘的增多，校验数据将越来越散，并发IO的几率也就越来越高。可以说，RAID 5在性能和可靠性之间找到了极佳的平衡。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/6/64/RAID_5.svg/220px-RAID_5.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点：无论是空间效率还是时间效率都达到了极佳&lt;/li&gt;
  &lt;li&gt;缺点：只能允许一块磁盘损坏&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;raid&quot;&gt;组合RAID&lt;/h2&gt;

&lt;p&gt;再发展下去，RAID的思想已经没有本质的改变了，只是优化RAID 5的思想，在可靠性和性能中间取舍。&lt;/p&gt;

&lt;p&gt;而且，还可以灵活使用上述的几种RAID进行组合，比如下图的&lt;code&gt;RAID 1+0&lt;/code&gt;和&lt;code&gt;RAID 0+1&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/RAID_10.svg/220px-RAID_10.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/RAID_01.svg/220px-RAID_01.svg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;RAID 1+0&lt;/code&gt;中，IO首先到达RAID 0控制器，然后被RAID 0控制器分发给下面的两个RAID 1控制器，RAID 1控制器将IO同时写入下面的两个磁盘。可以看到这种模式中，如果有一个磁盘损坏了，&lt;code&gt;其他的盘都能工作&lt;/code&gt;，不会影响。而4块磁盘实际上只能提供两块磁盘的容量。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;RAID 0+1&lt;/code&gt;中，IO首先到达RAID 1控制器，这个IO会同时分发给下面的两个RAID 0控制器，而每个RAID 0控制器再写入各自应该的磁盘上。可以看到这种模式中，如果有一个磁盘损坏了，&lt;code&gt;同一个RAID 0组的磁盘都不能工作了&lt;/code&gt;，不过整体还是不受影响的。而4块磁盘实际上只能提供两块磁盘的容量。&lt;/p&gt;

&lt;p&gt;再来看看&lt;code&gt;RAID 50&lt;/code&gt;，同其他的RAID组合思想一样，RAID 50是如下架构：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/9/9d/RAID_50.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;raid-1&quot;&gt;软件实现RAID&lt;/h2&gt;

&lt;p&gt;如果主机没有硬件的RAID控制器，可以使用操作系统自带的软RAID程序实现RAID。原理其实也很简单：程序将SCSI提交上来的磁盘信息通过配置好的RAID策略，分割合并再交给操作系统的上层模块；同时，操作系统对磁盘的读写操作都要经过这层软件进行重新的安排，然后转变成真正的磁盘操作指令。这层程序虽然起到了RAID的作用，但是程序本身的执行还是需要CPU参与运算，因此，软件RAID对系统性能有一定的影响，仅仅能够实现对磁盘的RAID功能。&lt;/p&gt;

&lt;h2 id=&quot;raid-2&quot;&gt;硬件RAID&lt;/h2&gt;

&lt;h3 id=&quot;raid-3&quot;&gt;RAID卡&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://i3.sinaimg.cn/IT/cr/2009/0721/2028045085.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;软件RAID虽然能够实现RAID，但是有如下缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CPU和内存占用&lt;/li&gt;
  &lt;li&gt;无法对操作系统所在分区进行RAID，因为程序本身运行在操作系统上&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了解决以上缺点，专用的硬件RAID卡被开发出来。这种RAID卡可以独立的实现RAID功能，不需要CPU和内存，也无需主机操作系统的参与，可见RAID卡本身就是一个完整的计算系统，有运算器和存储器，因此，RAID卡一般成本比较高。操作系统只需要有相应的RAID卡驱动程序即可。对于操作系统而言，经过RAID卡提交上来的磁盘，已经是经过RAID“虚拟过”的了，不是真实的物理磁盘数量。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;也有RAID功能集成在南桥芯片中的（南桥芯片直接与IO沟通）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于RAID卡连接了主机和磁盘（主机通过PCI总线与RAID卡连接，磁盘通过SCSI总线与RAID卡连接），因此RAID卡同时拥有PCI控制器和SCSI控制器，将PCI总线上传过来的磁盘操作指令经过翻译再通过RAID卡自己的SCSI控制器发出去，从而控制连接在RAID卡所在SCSI总线上的磁盘运转。RAID卡在实现RAID的过程中必然需要使用某种算法将映射关系储存下来，但是不同厂商的RAID卡做法不同，如果RAID卡坏了，磁盘就成了废材。因此，SNIA协会定义了一种DDF RAID信息标准格式，以使得不同厂商的RAID信息保持兼容。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;0通道RAID卡&lt;/code&gt;比较特殊，其本身没有SCSI控制器和总线接口，它需要利用同样插在主机PCI上的其他SCSI卡来识别磁盘（这些磁盘是链接在SCSI卡上的）。0通道RAID卡需要主板电路的支持。&lt;/p&gt;

&lt;p&gt;RAID卡与主机的接口目前有三种：IDE接口、SCSI接口和SATA接口。&lt;/p&gt;

&lt;h3 id=&quot;raid-4&quot;&gt;RAID卡上的内存&lt;/h3&gt;

&lt;p&gt;RAID卡在执行代码的时候需要RAM，所以RAID卡上有内存。不过RAID卡的内存还有一个用处，就是缓存。缓存的一个作用是适配高速的运算器和低速的IO控制器，另一个作用就是对IO进行缓存。就像磁盘本身内部的缓存一样，缓存用于对IO进行队列化和各种优化。对于上层的写IO，有两种处理策略：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code&gt;WriteBack&lt;/code&gt;模式：即当RAID控制器收到IO，并将IO缓存进队列后，就通知上层IO完成。这样做可以使上层系统“觉得”IO速度加快了，但是一个明显的问题是RAM是掉电数据就丢失了。所以一些高端的RAID卡还自带电池，在掉电时可以将缓存的数据刷回ROM，下次加电的时候再把缓存从ROM中加载回来，并将未完成的IO写入磁盘。&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;WriteThrough&lt;/code&gt;模式：即RAID控制器只有真正将数据写入磁盘后才会通知上层IO完成。这样保证了较高的可靠性。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;除了写缓存之外，RAID卡还具有读缓存能力，依靠复杂的缓存算法，“猜测”主机需要访问的数据，提前读入缓存，称为&lt;code&gt;预读(Prefetch)&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&quot;raid-5&quot;&gt;RAID的改进&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;RAID组再划分：随着单个磁盘的容量越来越大，一个RAID组的总容量也越来越大。这时，超大容量对于上层系统来说有些不够灵活。于是RAID控制器还支持将已经组好的RAID组进一步划分为虚拟磁盘。比如5块100G磁盘做RAID5，那么实际的容量为400G(100G校验)。如果不划分的话，操作系统将看到一块400G的物理磁盘；如果RAID组此时将400G划分为4块100G的虚拟磁盘，那么操作系统将看到4块100G的物理磁盘。虽然，此时的总容量没变，但是操作系统看到的物理磁盘并不是真正的物理盘，是RAID划分出来的虚拟磁盘。如果实际的物理磁盘损坏，对于操作系统而言没有任何影响，4块盘还是好好的。&lt;/li&gt;
  &lt;li&gt;一个通道多种类型：RAID还支持一个通道下划分出多种不同类型的RAID。比如8块100G的磁盘，可以将5块组成RAID5，另外3块组成RAID0。这样操作系统看到的将是两块物理磁盘，一块400G，一块300G。而且每个RAID类型还可以再像上面那样划分。&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Tue, 20 Jan 2015 00:00:00 +0800</pubDate>
				<link>/hardware/2015/01/20/storage-raid.html</link>
				<guid isPermaLink="true">/hardware/2015/01/20/storage-raid.html</guid>
			</item>
		
			<item>
				<title>Hello GitHub!</title>
				<description>&lt;p&gt;github pages： &lt;a href=&quot;http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html&quot;&gt;搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在上面这个链接的指引下，创建了kula这个项目，创建了主页。并且简单了解下来，发现GitHub不仅支持纯静态页面，还支持的是一种叫jekyll的静态页面生成模板引擎，似乎还不错。&lt;/p&gt;
</description>
				<pubDate>Mon, 19 Jan 2015 00:00:00 +0800</pubDate>
				<link>/life/2015/01/19/hello-github.html</link>
				<guid isPermaLink="true">/life/2015/01/19/hello-github.html</guid>
			</item>
		
	</channel>
</rss>
